{
  "_MODEL_CATALOG_NOTES": {
    "description": "Model categorization based on capabilities",
    "tiers": {
      "ARCHITECT (Tier 1)": "Opus, Kimi K2.5, Qwen3-235B-Thinking - Complex planning & reasoning",
      "BUILDER_HIGH (Tier 2)": "Sonnet-thinking-high, GPT-5.2-Codex, DeepSeek R1 - Complex coding",
      "BUILDER_MID (Tier 3)": "Sonnet, Gemini Pro, MiniMax M2.1 - Standard development",
      "LIBRARIAN (Tier 4)": "Haiku, Gemini Flash, OpenRouter Free - Context, search",
      "SPRINTER (Tier 5)": "Cerebras GLM-4.7, GLM-4.7 Synthetic - High-volume code"
    }
  },
  
  "synthetic-GLM-4.7": {
    "type": "custom_openai",
    "name": "hf:zai-org/GLM-4.7",
    "custom_endpoint": {
      "url": "https://api.synthetic.new/openai/v1/",
      "api_key": "$SYN_API_KEY"
    },
    "context_length": 200000,
    "max_output": 16000,
    "tier": 5,
    "workload": ["coding", "sprinter"],
    "capabilities": ["agentic_coding", "tool_use", "reasoning"],
    "supported_settings": ["temperature", "seed", "top_p"]
  },
  "synthetic-MiniMax-M2.1": {
    "type": "custom_openai",
    "name": "hf:MiniMaxAI/MiniMax-M2.1",
    "custom_endpoint": {
      "url": "https://api.synthetic.new/openai/v1/",
      "api_key": "$SYN_API_KEY"
    },
    "context_length": 1000000,
    "max_output": 1000000,
    "tier": 3,
    "workload": ["coding", "builder"],
    "capabilities": ["multilang_coding", "tool_use", "agent_frameworks"],
    "supported_settings": ["temperature", "seed", "top_p"]
  },
  "synthetic-Kimi-K2-Thinking": {
    "type": "custom_openai",
    "name": "hf:moonshotai/Kimi-K2-Thinking",
    "custom_endpoint": {
      "url": "https://api.synthetic.new/openai/v1/",
      "api_key": "$SYN_API_KEY"
    },
    "context_length": 256000,
    "max_output": 32000,
    "tier": 2,
    "workload": ["reasoning", "builder_high"],
    "capabilities": ["thinking", "moe", "agent_swarms"],
    "supported_settings": ["temperature", "seed", "top_p"]
  },
  "synthetic-Kimi-K2.5-Thinking": {
    "type": "custom_openai",
    "name": "hf:moonshotai/Kimi-K2.5",
    "custom_endpoint": {
      "url": "https://api.synthetic.new/openai/v1/",
      "api_key": "$SYN_API_KEY"
    },
    "context_length": 256000,
    "max_output": 32000,
    "tier": 1,
    "workload": ["orchestrator", "reasoning", "architect"],
    "capabilities": ["thinking", "moe", "agent_swarms", "vision"],
    "supported_settings": ["temperature", "seed", "top_p"]
  },
  "synthetic-hf-deepseek-ai-DeepSeek-R1-0528": {
    "type": "custom_openai",
    "name": "hf:deepseek-ai/DeepSeek-R1-0528",
    "custom_endpoint": {
      "url": "https://api.synthetic.new/openai/v1/",
      "api_key": "$SYN_API_KEY"
    },
    "context_length": 131072,
    "max_output": 131072,
    "tier": 2,
    "workload": ["reasoning", "builder_high"],
    "capabilities": ["thinking", "reasoning", "math", "moe"],
    "supported_settings": ["temperature", "seed", "top_p"]
  },
  "synthetic-hf-MiniMaxAI-MiniMax-M2.1": {
    "type": "custom_openai",
    "name": "hf:MiniMaxAI/MiniMax-M2.1",
    "custom_endpoint": {
      "url": "https://api.synthetic.new/openai/v1/",
      "api_key": "$SYN_API_KEY"
    },
    "context_length": 1000000,
    "max_output": 1000000,
    "tier": 3,
    "workload": ["coding", "builder"],
    "capabilities": ["multilang_coding", "tool_use", "agent_frameworks"],
    "supported_settings": ["temperature", "seed", "top_p"]
  },
  "synthetic-hf-Qwen-Qwen3-235B-A22B-Thinking-2507": {
    "type": "custom_openai",
    "name": "hf:Qwen/Qwen3-235B-A22B-Thinking-2507",
    "custom_endpoint": {
      "url": "https://api.synthetic.new/openai/v1/",
      "api_key": "$SYN_API_KEY"
    },
    "context_length": 262144,
    "max_output": 16384,
    "tier": 1,
    "workload": ["orchestrator", "reasoning", "architect"],
    "capabilities": ["thinking", "moe", "math", "multilingual"],
    "supported_settings": ["temperature", "seed", "top_p"]
  },
  "synthetic-hf-zai-org-GLM-4.7": {
    "type": "custom_openai",
    "name": "hf:zai-org/GLM-4.7",
    "custom_endpoint": {
      "url": "https://api.synthetic.new/openai/v1/",
      "api_key": "$SYN_API_KEY"
    },
    "context_length": 200000,
    "max_output": 16000,
    "tier": 5,
    "workload": ["coding", "sprinter"],
    "capabilities": ["agentic_coding", "tool_use", "deep_thinking"],
    "supported_settings": ["temperature", "seed", "top_p"]
  },
  "chatgpt-gpt-5.2": {
    "type": "chatgpt",
    "name": "gpt-5.2",
    "context_length": 400000,
    "max_output": 32000,
    "tier": 2,
    "workload": ["reasoning", "coding", "builder_high"],
    "capabilities": ["reasoning", "long_context", "multimodal"],
    "supported_settings": ["temperature", "top_p", "reasoning_effort"]
  },
  "chatgpt-gpt-5.2-codex": {
    "type": "chatgpt",
    "name": "gpt-5.2-codex",
    "context_length": 400000,
    "max_output": 32000,
    "tier": 2,
    "workload": ["coding", "builder_high"],
    "capabilities": ["agentic_coding", "migrations", "refactoring", "cybersecurity"],
    "supported_settings": ["temperature", "top_p", "reasoning_effort"]
  },
  "openrouter-stepfun-step-3.5-flash-free": {
    "type": "openrouter",
    "name": "stepfun/step-3.5-flash-free",
    "context_length": 128000,
    "max_output": 8000,
    "tier": 4,
    "workload": ["librarian"],
    "capabilities": ["fast", "free"],
    "supported_settings": ["temperature", "top_p"]
  },
  "openrouter-arcee-ai-trinity-large-preview-free": {
    "type": "openrouter",
    "name": "arcee-ai/trinity-large-preview-free",
    "context_length": 128000,
    "max_output": 8000,
    "tier": 4,
    "workload": ["librarian"],
    "capabilities": ["fast", "free"],
    "supported_settings": ["temperature", "top_p"]
  },
  "Gemini-3": {
    "type": "gemini",
    "name": "gemini-3-pro-preview",
    "context_length": 200000,
    "supported_settings": ["temperature", "top_p", "thinking_enabled", "thinking_level"]
  },
  "Gemini-3-Long-Context": {
    "type": "gemini",
    "name": "gemini-3-pro-preview",
    "context_length": 1000000,
    "supported_settings": ["temperature", "top_p", "thinking_enabled", "thinking_level"]
  },
  "Cerebras-GLM-4.7": {
    "type": "cerebras",
    "name": "zai-glm-4.7",
    "custom_endpoint": {
      "url": "https://api.cerebras.ai/v1",
      "api_key": "$CEREBRAS_API_KEY"
    },
    "context_length": 131072,
    "supported_settings": ["temperature", "seed", "top_p"]
  },
  "claude-code-claude-haiku-4-5-20251001": {
    "type": "claude_code",
    "name": "claude-haiku-4-5-20251001",
    "context_length": 200000,
    "supported_settings": ["temperature", "extended_thinking", "budget_tokens"]
  },
  "claude-code-claude-sonnet-4-5-20250929": {
    "type": "claude_code",
    "name": "claude-sonnet-4-5-20250929",
    "context_length": 200000,
    "supported_settings": ["temperature", "extended_thinking", "budget_tokens"]
  },
  "claude-code-claude-opus-4-5-20251101": {
    "type": "claude_code",
    "name": "claude-opus-4-5-20251101",
    "context_length": 200000,
    "supported_settings": ["temperature", "extended_thinking", "budget_tokens", "interleaved_thinking"]
  },
  "antigravity-claude-opus-4-5-thinking-low": {
    "type": "antigravity",
    "name": "claude-opus-4-5-20251101",
    "context_length": 200000,
    "supported_settings": ["temperature", "extended_thinking", "budget_tokens", "interleaved_thinking"]
  },
  "antigravity-claude-opus-4-5-thinking-medium": {
    "type": "antigravity",
    "name": "claude-opus-4-5-20251101",
    "context_length": 200000,
    "supported_settings": ["temperature", "extended_thinking", "budget_tokens", "interleaved_thinking"]
  },
  "antigravity-claude-opus-4-5-thinking-high": {
    "type": "antigravity",
    "name": "claude-opus-4-5-20251101",
    "context_length": 200000,
    "supported_settings": ["temperature", "extended_thinking", "budget_tokens", "interleaved_thinking"]
  },
  "antigravity-gemini-3-pro-low": {
    "type": "antigravity",
    "name": "gemini-3-pro-preview",
    "context_length": 200000,
    "supported_settings": ["temperature", "top_p"]
  },
  "antigravity-gemini-3-pro-high": {
    "type": "antigravity",
    "name": "gemini-3-pro-preview",
    "context_length": 200000,
    "supported_settings": ["temperature", "top_p"]
  },
  "antigravity-gemini-3-flash": {
    "type": "antigravity",
    "name": "gemini-3-flash-preview",
    "context_length": 200000,
    "supported_settings": ["temperature", "top_p"]
  },
  "antigravity-claude-sonnet-4-5": {
    "type": "antigravity",
    "name": "claude-sonnet-4-5-20250929",
    "context_length": 200000,
    "supported_settings": ["temperature", "extended_thinking", "budget_tokens"]
  },
  "antigravity-claude-sonnet-4-5-thinking-low": {
    "type": "antigravity",
    "name": "claude-sonnet-4-5-20250929",
    "context_length": 200000,
    "supported_settings": ["temperature", "extended_thinking", "budget_tokens"]
  },
  "antigravity-claude-sonnet-4-5-thinking-medium": {
    "type": "antigravity",
    "name": "claude-sonnet-4-5-20250929",
    "context_length": 200000,
    "supported_settings": ["temperature", "extended_thinking", "budget_tokens"]
  },
  "antigravity-claude-sonnet-4-5-thinking-high": {
    "type": "antigravity",
    "name": "claude-sonnet-4-5-20250929",
    "context_length": 200000,
    "supported_settings": ["temperature", "extended_thinking", "budget_tokens"]
  },
  "zai-glm-4.6-coding": {
    "type": "zai_coding",
    "name": "glm-4.6",
    "context_length": 200000,
    "supported_settings": ["temperature", "top_p"]
  },
  "zai-glm-4.6-api": {
    "type": "zai_api",
    "name": "glm-4.6",
    "context_length": 200000,
    "supported_settings": ["temperature", "top_p"]
  },
  "zai-glm-4.7-coding": {
    "type": "zai_coding",
    "name": "glm-4.7",
    "context_length": 200000,
    "supported_settings": ["temperature", "top_p"]
  },
  "zai-glm-4.7-api": {
    "type": "zai_api",
    "name": "glm-4.7",
    "context_length": 200000,
    "supported_settings": ["temperature", "top_p"]
  },

  "_GITHUB_MODELS_API_NOTES": {
    "description": "Models available via GitHub Models API (models.github.ai)",
    "auth": "Uses GH_TOKEN from 'gh auth token' command",
    "endpoint": "https://models.github.ai/inference",
    "tiers": {
      "gpt-4.1/gpt-4o": "Tier 2-3 - Strong reasoning and coding",
      "grok-3": "Tier 2 - xAI reasoning model",
      "grok-3-mini": "Tier 3 - xAI reasoning (faster)",
      "deepseek-r1": "Tier 2 - 671B reasoning model",
      "phi-4": "Tier 4 - Microsoft small model"
    }
  },

  "github-gpt-4.1": {
    "type": "custom_openai",
    "name": "openai/gpt-4.1",
    "custom_endpoint": {
      "url": "https://models.github.ai/inference/",
      "api_key": "$GH_TOKEN"
    },
    "context_length": 128000,
    "max_output": 16384,
    "tier": 2,
    "workload": ["reasoning", "coding", "builder_high"],
    "capabilities": ["reasoning", "code_gen", "multimodal"],
    "supported_settings": ["temperature", "top_p"]
  },
  "github-gpt-4.1-mini": {
    "type": "custom_openai",
    "name": "openai/gpt-4.1-mini",
    "custom_endpoint": {
      "url": "https://models.github.ai/inference/",
      "api_key": "$GH_TOKEN"
    },
    "context_length": 128000,
    "max_output": 16384,
    "tier": 3,
    "workload": ["coding", "builder"],
    "capabilities": ["code_gen", "fast"],
    "supported_settings": ["temperature", "top_p"]
  },
  "github-gpt-4o": {
    "type": "custom_openai",
    "name": "openai/gpt-4o",
    "custom_endpoint": {
      "url": "https://models.github.ai/inference/",
      "api_key": "$GH_TOKEN"
    },
    "context_length": 128000,
    "max_output": 16384,
    "tier": 3,
    "workload": ["coding", "reasoning", "builder"],
    "capabilities": ["reasoning", "code_gen", "multimodal"],
    "supported_settings": ["temperature", "top_p"]
  },
  "github-gpt-4o-mini": {
    "type": "custom_openai",
    "name": "openai/gpt-4o-mini",
    "custom_endpoint": {
      "url": "https://models.github.ai/inference/",
      "api_key": "$GH_TOKEN"
    },
    "context_length": 128000,
    "max_output": 16384,
    "tier": 4,
    "workload": ["librarian", "coding"],
    "capabilities": ["code_gen", "fast", "cheap"],
    "supported_settings": ["temperature", "top_p"]
  },
  "github-grok-3": {
    "type": "custom_openai",
    "name": "xai/grok-3",
    "custom_endpoint": {
      "url": "https://models.github.ai/inference/",
      "api_key": "$GH_TOKEN"
    },
    "context_length": 131072,
    "max_output": 16384,
    "tier": 2,
    "workload": ["reasoning", "orchestrator", "builder_high"],
    "capabilities": ["reasoning", "code_gen", "deep_thinking"],
    "supported_settings": ["temperature", "top_p"]
  },
  "github-grok-3-mini": {
    "type": "custom_openai",
    "name": "xai/grok-3-mini",
    "custom_endpoint": {
      "url": "https://models.github.ai/inference/",
      "api_key": "$GH_TOKEN"
    },
    "context_length": 131072,
    "max_output": 8192,
    "tier": 3,
    "workload": ["reasoning", "coding", "builder"],
    "capabilities": ["reasoning", "fast"],
    "supported_settings": ["temperature", "top_p"]
  },
  "github-deepseek-r1": {
    "type": "custom_openai",
    "name": "deepseek/deepseek-r1",
    "custom_endpoint": {
      "url": "https://models.github.ai/inference/",
      "api_key": "$GH_TOKEN"
    },
    "context_length": 131072,
    "max_output": 16384,
    "tier": 2,
    "workload": ["reasoning", "builder_high"],
    "capabilities": ["thinking", "reasoning", "math", "moe"],
    "supported_settings": ["temperature", "top_p"]
  },
  "github-phi-4": {
    "type": "custom_openai",
    "name": "microsoft/phi-4",
    "custom_endpoint": {
      "url": "https://models.github.ai/inference/",
      "api_key": "$GH_TOKEN"
    },
    "context_length": 16384,
    "max_output": 4096,
    "tier": 4,
    "workload": ["librarian", "coding"],
    "capabilities": ["fast", "efficient", "small"],
    "supported_settings": ["temperature", "top_p"]
  }
}
