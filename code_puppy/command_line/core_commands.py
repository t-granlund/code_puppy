"""Command handlers for Code Puppy - CORE commands.

This module contains @register_command decorated handlers that are automatically
discovered by the command registry system.
"""

import os

from code_puppy.command_line.agent_menu import interactive_agent_picker
from code_puppy.command_line.command_registry import register_command
from code_puppy.command_line.model_picker_completion import update_model_in_input
from code_puppy.command_line.motd import print_motd
from code_puppy.command_line.utils import make_directory_table
from code_puppy.config import finalize_autosave_session
from code_puppy.messaging import emit_error, emit_info
from code_puppy.tools.tools_content import tools_content


# Import get_commands_help from command_handler to avoid circular imports
# This will be defined in command_handler.py
def get_commands_help():
    """Lazy import to avoid circular dependency."""
    from code_puppy.command_line.command_handler import get_commands_help as _gch

    return _gch()


@register_command(
    name="help",
    description="Show this help message",
    usage="/help, /h",
    aliases=["h"],
    category="core",
)
def handle_help_command(command: str) -> bool:
    """Show commands help."""
    import uuid

    from code_puppy.messaging import emit_info

    group_id = str(uuid.uuid4())
    help_text = get_commands_help()
    emit_info(help_text, message_group_id=group_id)
    return True


@register_command(
    name="cd",
    description="Change directory or show directories",
    usage="/cd <dir>",
    category="core",
)
def handle_cd_command(command: str) -> bool:
    """Change directory or list current directory."""
    # Use shlex.split to handle quoted paths properly
    import shlex

    from code_puppy.messaging import emit_error, emit_info, emit_success

    try:
        tokens = shlex.split(command)
    except ValueError:
        # Fallback to simple split if shlex fails
        tokens = command.split()
    if len(tokens) == 1:
        try:
            table = make_directory_table()
            emit_info(table)
        except Exception as e:
            emit_error(f"Error listing directory: {e}")
        return True
    elif len(tokens) == 2:
        dirname = tokens[1]
        target = os.path.expanduser(dirname)
        if not os.path.isabs(target):
            target = os.path.join(os.getcwd(), target)
        if os.path.isdir(target):
            os.chdir(target)
            emit_success(f"Changed directory to: {target}")
        else:
            emit_error(f"Not a directory: {dirname}")
        return True
    return True


@register_command(
    name="tools",
    description="Show available tools and capabilities",
    usage="/tools",
    category="core",
)
def handle_tools_command(command: str) -> bool:
    """Display available tools."""
    from rich.markdown import Markdown

    from code_puppy.messaging import emit_info

    markdown_content = Markdown(tools_content)
    emit_info(markdown_content)
    return True


@register_command(
    name="motd",
    description="Show the latest message of the day (MOTD)",
    usage="/motd",
    category="core",
)
def handle_motd_command(command: str) -> bool:
    """Show message of the day."""
    try:
        print_motd(force=True)
    except Exception:
        # Handle printing errors gracefully
        pass
    return True


@register_command(
    name="paste",
    description="Paste image from clipboard (same as F3, or Ctrl+V with image)",
    usage="/paste, /clipboard, /cb",
    aliases=["clipboard", "cb"],
    category="core",
)
def handle_paste_command(command: str) -> bool:
    """Paste an image from the clipboard into the pending attachments."""
    from code_puppy.command_line.clipboard import (
        capture_clipboard_image_to_pending,
        get_clipboard_manager,
        has_image_in_clipboard,
    )
    from code_puppy.messaging import emit_info, emit_success, emit_warning

    if not has_image_in_clipboard():
        emit_warning("No image found in clipboard")
        emit_info("Copy an image (screenshot, from browser, etc.) and try again")
        return True

    placeholder = capture_clipboard_image_to_pending()
    if placeholder:
        manager = get_clipboard_manager()
        count = manager.get_pending_count()
        emit_success(f"üìã {placeholder}")
        emit_info(f"Total pending clipboard images: {count}")
        emit_info("Type your prompt and press Enter to send with the image(s)")
    else:
        emit_warning("Failed to capture clipboard image")

    return True


@register_command(
    name="tutorial",
    description="Run the interactive tutorial wizard",
    usage="/tutorial",
    category="core",
)
def handle_tutorial_command(command: str) -> bool:
    """Run the interactive tutorial wizard.

    Usage:
        /tutorial  - Run the tutorial (can be run anytime)
    """
    import asyncio
    import concurrent.futures

    from code_puppy.command_line.onboarding_wizard import (
        reset_onboarding,
        run_onboarding_wizard,
    )
    from code_puppy.model_switching import set_model_and_reload_agent

    # Always reset so user can re-run the tutorial anytime
    reset_onboarding()

    # Run the async wizard in a thread pool (same pattern as agent picker)
    with concurrent.futures.ThreadPoolExecutor() as executor:
        future = executor.submit(lambda: asyncio.run(run_onboarding_wizard()))
        result = future.result(timeout=300)  # 5 min timeout

    if result == "chatgpt":
        emit_info("üîê Starting ChatGPT OAuth flow...")
        from code_puppy.plugins.chatgpt_oauth.oauth_flow import run_oauth_flow

        run_oauth_flow()
        set_model_and_reload_agent("chatgpt-gpt-5.3-codex")
    elif result == "claude":
        emit_info("üîê Starting Claude Code OAuth flow...")
        from code_puppy.plugins.claude_code_oauth.register_callbacks import (
            _perform_authentication,
        )

        _perform_authentication()
        set_model_and_reload_agent("claude-code-claude-opus-4-6")
    elif result == "completed":
        emit_info("üéâ Tutorial complete! Happy coding!")
    elif result == "skipped":
        emit_info("‚è≠Ô∏è Tutorial skipped. Run /tutorial anytime!")

    return True


@register_command(
    name="exit",
    description="Exit interactive mode",
    usage="/exit, /quit",
    aliases=["quit"],
    category="core",
)
def handle_exit_command(command: str) -> bool:
    """Exit the interactive session."""
    from code_puppy.messaging import emit_success

    try:
        emit_success("Goodbye!")
    except Exception:
        # Handle emit errors gracefully
        pass
    # Signal to the main app that we want to exit
    # The actual exit handling is done in main.py
    return True


@register_command(
    name="agent",
    description="Switch to a different agent or show available agents",
    usage="/agent <name>, /a <name>",
    aliases=["a"],
    category="core",
)
def handle_agent_command(command: str) -> bool:
    """Handle agent switching."""
    from rich.text import Text

    from code_puppy.agents import (
        get_agent_descriptions,
        get_available_agents,
        get_current_agent,
        set_current_agent,
    )
    from code_puppy.messaging import emit_error, emit_info, emit_success, emit_warning

    tokens = command.split()

    if len(tokens) == 1:
        # Show interactive agent picker
        try:
            # Run the async picker using asyncio utilities
            # Since we're called from an async context but this function is sync,
            # we need to carefully schedule and wait for the coroutine
            import asyncio
            import concurrent.futures
            import uuid

            # Create a new event loop in a thread and run the picker there
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(
                    lambda: asyncio.run(interactive_agent_picker())
                )
                selected_agent = future.result(timeout=300)  # 5 min timeout

            if selected_agent:
                current_agent = get_current_agent()
                # Check if we're already using this agent
                if current_agent.name == selected_agent:
                    group_id = str(uuid.uuid4())
                    emit_info(
                        f"Already using agent: {current_agent.display_name}",
                        message_group=group_id,
                    )
                    return True

                # Switch to the new agent
                group_id = str(uuid.uuid4())
                new_session_id = finalize_autosave_session()
                if not set_current_agent(selected_agent):
                    emit_warning(
                        "Agent switch failed after autosave rotation. Your context was preserved.",
                        message_group=group_id,
                    )
                    return True

                new_agent = get_current_agent()
                new_agent.reload_code_generation_agent()
                emit_success(
                    f"Switched to agent: {new_agent.display_name}",
                    message_group=group_id,
                )
                emit_info(f"{new_agent.description}", message_group=group_id)
                emit_info(
                    Text.from_markup(
                        f"[dim]Auto-save session rotated to: {new_session_id}[/dim]"
                    ),
                    message_group=group_id,
                )
            else:
                emit_warning("Agent selection cancelled")
            return True
        except Exception as e:
            # Fallback to old behavior if picker fails
            import traceback
            import uuid

            emit_warning(f"Interactive picker failed: {e}")
            emit_warning(f"Traceback: {traceback.format_exc()}")

            # Show current agent and available agents
            current_agent = get_current_agent()
            available_agents = get_available_agents()
            descriptions = get_agent_descriptions()

            # Generate a group ID for all messages in this command
            group_id = str(uuid.uuid4())

            emit_info(
                Text.from_markup(
                    f"[bold green]Current Agent:[/bold green] {current_agent.display_name}"
                ),
                message_group=group_id,
            )
            emit_info(
                Text.from_markup(f"[dim]{current_agent.description}[/dim]\n"),
                message_group=group_id,
            )

            emit_info(
                Text.from_markup("[bold magenta]Available Agents:[/bold magenta]"),
                message_group=group_id,
            )
            for name, display_name in available_agents.items():
                description = descriptions.get(name, "No description")
                current_marker = (
                    " [green]‚Üê current[/green]" if name == current_agent.name else ""
                )
                emit_info(
                    Text.from_markup(
                        f"  [cyan]{name:<12}[/cyan] {display_name}{current_marker}"
                    ),
                    message_group=group_id,
                )
                emit_info(f"    {description}", message_group=group_id)

            emit_info(
                Text.from_markup("\n[yellow]Usage:[/yellow] /agent <agent-name>"),
                message_group=group_id,
            )
            return True

    elif len(tokens) == 2:
        agent_name = tokens[1].lower()

        # Generate a group ID for all messages in this command
        import uuid

        group_id = str(uuid.uuid4())
        available_agents = get_available_agents()

        if agent_name not in available_agents:
            emit_error(f"Agent '{agent_name}' not found", message_group=group_id)
            emit_warning(
                f"Available agents: {', '.join(available_agents.keys())}",
                message_group=group_id,
            )
            return True

        current_agent = get_current_agent()
        if current_agent.name == agent_name:
            emit_info(
                f"Already using agent: {current_agent.display_name}",
                message_group=group_id,
            )
            return True

        new_session_id = finalize_autosave_session()
        if not set_current_agent(agent_name):
            emit_warning(
                "Agent switch failed after autosave rotation. Your context was preserved.",
                message_group=group_id,
            )
            return True

        new_agent = get_current_agent()
        new_agent.reload_code_generation_agent()
        emit_success(
            f"Switched to agent: {new_agent.display_name}",
            message_group=group_id,
        )
        emit_info(f"{new_agent.description}", message_group=group_id)
        emit_info(
            Text.from_markup(
                f"[dim]Auto-save session rotated to: {new_session_id}[/dim]"
            ),
            message_group=group_id,
        )
        return True
    else:
        emit_warning("Usage: /agent [agent-name]")
        return True


async def interactive_model_picker() -> str | None:
    """Show an interactive arrow-key selector to pick a model (async version).

    Returns:
        The selected model name, or None if cancelled
    """
    import sys
    import time

    from rich.console import Console
    from rich.panel import Panel
    from rich.text import Text

    from code_puppy.command_line.model_picker_completion import (
        get_active_model,
        load_model_names,
    )
    from code_puppy.tools.command_runner import set_awaiting_user_input
    from code_puppy.tools.common import arrow_select_async

    # Load available models
    model_names = load_model_names()
    current_model = get_active_model()

    # Build choices with current model indicator
    choices = []
    for model_name in model_names:
        if model_name == current_model:
            choices.append(f"‚úì {model_name} (current)")
        else:
            choices.append(f"  {model_name}")

    # Create panel content
    panel_content = Text()
    panel_content.append("ü§ñ Select a model to use\n", style="bold cyan")
    panel_content.append("Current model: ", style="dim")
    panel_content.append(current_model, style="bold green")

    # Display panel
    panel = Panel(
        panel_content,
        title="[bold white]Model Selection[/bold white]",
        border_style="cyan",
        padding=(1, 2),
    )

    # Pause spinners BEFORE showing panel
    set_awaiting_user_input(True)
    time.sleep(0.3)  # Let spinners fully stop

    local_console = Console()
    emit_info("")
    local_console.print(panel)
    emit_info("")

    # Flush output before prompt_toolkit takes control
    sys.stdout.flush()
    sys.stderr.flush()
    time.sleep(0.1)

    selected_model = None

    try:
        # Final flush
        sys.stdout.flush()

        # Show arrow-key selector (async version)
        choice = await arrow_select_async(
            "üí≠ Which model would you like to use?",
            choices,
        )

        # Extract model name from choice (remove prefix and suffix)
        if choice:
            # Remove the "‚úì " or "  " prefix and " (current)" suffix if present
            selected_model = choice.strip().lstrip("‚úì").strip()
            if selected_model.endswith(" (current)"):
                selected_model = selected_model[:-10].strip()

    except (KeyboardInterrupt, EOFError):
        emit_error("Cancelled by user")
        selected_model = None

    finally:
        set_awaiting_user_input(False)

    return selected_model


@register_command(
    name="model",
    description="Set active model",
    usage="/model, /m <model>",
    aliases=["m"],
    category="core",
)
def handle_model_command(command: str) -> bool:
    """Set the active model."""
    import asyncio

    from code_puppy.command_line.model_picker_completion import (
        get_active_model,
        load_model_names,
        set_active_model,
    )
    from code_puppy.messaging import emit_success, emit_warning

    tokens = command.split()

    # If just /model or /m with no args, show interactive picker
    if len(tokens) == 1:
        try:
            # Run the async picker using asyncio utilities
            # Since we're called from an async context but this function is sync,
            # we need to carefully schedule and wait for the coroutine
            import concurrent.futures

            # Create a new event loop in a thread and run the picker there
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(
                    lambda: asyncio.run(interactive_model_picker())
                )
                selected_model = future.result(timeout=300)  # 5 min timeout

            if selected_model:
                set_active_model(selected_model)
                emit_success(f"Active model set and loaded: {selected_model}")
            else:
                emit_warning("Model selection cancelled")
            return True
        except Exception as e:
            # Fallback to old behavior if picker fails
            import traceback

            emit_warning(f"Interactive picker failed: {e}")
            emit_warning(f"Traceback: {traceback.format_exc()}")
            model_names = load_model_names()
            emit_warning("Usage: /model <model-name> or /m <model-name>")
            emit_warning(f"Available models: {', '.join(model_names)}")
            return True

    # Handle both /model and /m for backward compatibility
    model_command = command
    if command.startswith("/model"):
        # Convert /model to /m for internal processing
        model_command = command.replace("/model", "/m", 1)

    # If model matched, set it
    new_input = update_model_in_input(model_command)
    if new_input is not None:
        model = get_active_model()
        emit_success(f"Active model set and loaded: {model}")
        return True

    # If no model matched, show error
    model_names = load_model_names()
    emit_warning("Usage: /model <model-name> or /m <model-name>")
    emit_warning(f"Available models: {', '.join(model_names)}")
    return True


@register_command(
    name="add_model",
    description="Browse and add models from models.dev catalog",
    usage="/add_model",
    category="core",
)
def handle_add_model_command(command: str) -> bool:
    """Launch interactive model browser TUI."""
    from code_puppy.command_line.add_model_menu import interactive_model_picker
    from code_puppy.tools.command_runner import set_awaiting_user_input

    set_awaiting_user_input(True)
    try:
        # interactive_model_picker is now synchronous - no async complications!
        result = interactive_model_picker()

        if result:
            emit_info("Successfully added model configuration")
        return True
    except KeyboardInterrupt:
        # User cancelled - this is expected behavior
        return True
    except Exception as e:
        emit_error(f"Failed to launch model browser: {e}")
        return False
    finally:
        set_awaiting_user_input(False)


@register_command(
    name="model_settings",
    description="Configure per-model settings (temperature, seed, etc.)",
    usage="/model_settings [--show [model_name]]",
    aliases=["ms"],
    category="config",
)
def handle_model_settings_command(command: str) -> bool:
    """Launch interactive model settings TUI.

    Opens a TUI showing all available models. Select a model to configure
    its settings (temperature, seed, etc.). ESC closes the TUI.

    Use --show [model_name] to display current settings without the TUI.
    """
    from code_puppy.command_line.model_settings_menu import (
        interactive_model_settings,
        show_model_settings_summary,
    )
    from code_puppy.messaging import emit_error, emit_info, emit_success, emit_warning
    from code_puppy.tools.command_runner import set_awaiting_user_input

    tokens = command.split()

    # Check for --show flag to just display current settings
    if "--show" in tokens:
        model_name = None
        for t in tokens[1:]:
            if not t.startswith("--"):
                model_name = t
                break
        show_model_settings_summary(model_name)
        return True

    set_awaiting_user_input(True)
    try:
        result = interactive_model_settings()

        if result:
            emit_success("Model settings updated successfully")

        # Always reload the active agent so settings take effect
        from code_puppy.agents import get_current_agent

        try:
            current_agent = get_current_agent()
            current_agent.reload_code_generation_agent()
            emit_info("Active agent reloaded")
        except Exception as reload_error:
            emit_warning(f"Agent reload failed: {reload_error}")

        return True
    except KeyboardInterrupt:
        return True
    except Exception as e:
        emit_error(f"Failed to launch model settings: {e}")
        return False
    finally:
        set_awaiting_user_input(False)


@register_command(
    name="mcp",
    description="Manage MCP servers (list, start, stop, status, etc.)",
    usage="/mcp",
    category="core",
)
def handle_mcp_command(command: str) -> bool:
    """Handle MCP server management."""
    from code_puppy.command_line.mcp import MCPCommandHandler

    handler = MCPCommandHandler()
    return handler.handle_mcp_command(command)


@register_command(
    name="api",
    description="Manage the Code Puppy API server",
    usage="/api [start|stop|status]",
    category="core",
    detailed_help="Start, stop, or check status of the local FastAPI server for GUI integration.",
)
def handle_api_command(command: str) -> bool:
    """Handle the /api command."""
    import os
    import signal
    import subprocess
    import sys
    from pathlib import Path

    from code_puppy.config import STATE_DIR
    from code_puppy.messaging import emit_error, emit_info, emit_success

    parts = command.split()
    subcommand = parts[1] if len(parts) > 1 else "status"

    pid_file = Path(STATE_DIR) / "api_server.pid"

    if subcommand == "start":
        # Check if already running
        if pid_file.exists():
            try:
                pid = int(pid_file.read_text().strip())
                os.kill(pid, 0)  # Check if process exists
                emit_info(f"API server already running (PID {pid})")
                return True
            except (OSError, ValueError):
                pid_file.unlink(missing_ok=True)  # Stale PID file

        # Start the server in background
        emit_info("Starting API server on http://127.0.0.1:8765 ...")
        proc = subprocess.Popen(
            [sys.executable, "-m", "code_puppy.api.main"],
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
            start_new_session=True,
        )
        pid_file.parent.mkdir(parents=True, exist_ok=True)
        pid_file.write_text(str(proc.pid))
        emit_success(f"API server started (PID {proc.pid})")
        emit_info("Docs available at http://127.0.0.1:8765/docs")
        return True

    elif subcommand == "stop":
        if not pid_file.exists():
            emit_info("API server is not running")
            return True

        try:
            pid = int(pid_file.read_text().strip())
            os.kill(pid, signal.SIGTERM)
            pid_file.unlink()
            emit_success(f"API server stopped (PID {pid})")
        except (OSError, ValueError) as e:
            pid_file.unlink(missing_ok=True)
            emit_error(f"Error stopping server: {e}")
        return True

    elif subcommand == "status":
        if not pid_file.exists():
            emit_info("API server is not running")
            return True

        try:
            pid = int(pid_file.read_text().strip())
            os.kill(pid, 0)  # Check if process exists
            emit_success(f"API server is running (PID {pid})")
            emit_info("URL: http://127.0.0.1:8765")
            emit_info("Docs: http://127.0.0.1:8765/docs")
        except (OSError, ValueError):
            pid_file.unlink(missing_ok=True)
            emit_info("API server is not running (stale PID file removed)")
        return True

    else:
        emit_error(f"Unknown subcommand: {subcommand}")
        emit_info("Usage: /api [start|stop|status]")
        return True


@register_command(
    name="generate-pr-description",
    description="Generate comprehensive PR description",
    usage="/generate-pr-description [@dir]",
    category="core",
)
def handle_generate_pr_description_command(command: str) -> str:
    """Generate a PR description."""
    # Parse directory argument (e.g., /generate-pr-description @some/dir)
    tokens = command.split()
    directory_context = ""
    for t in tokens:
        if t.startswith("@"):
            directory_context = f" Please work in the directory: {t[1:]}"
            break

    # Hard-coded prompt from user requirements
    pr_prompt = f"""Generate a comprehensive PR description for my current branch changes. Follow these steps:

 1 Discover the changes: Use git CLI to find the base branch (usually main/master/develop) and get the list of changed files, commits, and diffs.
 2 Analyze the code: Read and analyze all modified files to understand:
    ‚Ä¢ What functionality was added/changed/removed
    ‚Ä¢ The technical approach and implementation details
    ‚Ä¢ Any architectural or design pattern changes
    ‚Ä¢ Dependencies added/removed/updated
 3 Generate a structured PR description with these sections:
    ‚Ä¢ Title: Concise, descriptive title (50 chars max)
    ‚Ä¢ Summary: Brief overview of what this PR accomplishes
    ‚Ä¢ Changes Made: Detailed bullet points of specific changes
    ‚Ä¢ Technical Details: Implementation approach, design decisions, patterns used
    ‚Ä¢ Files Modified: List of key files with brief description of changes
    ‚Ä¢ Testing: What was tested and how (if applicable)
    ‚Ä¢ Breaking Changes: Any breaking changes (if applicable)
    ‚Ä¢ Additional Notes: Any other relevant information
 4 Create a markdown file: Generate a PR_DESCRIPTION.md file with proper GitHub markdown formatting that I can directly copy-paste into GitHub's PR
   description field. Use proper markdown syntax with headers, bullet points, code blocks, and formatting.
 5 Make it review-ready: Ensure the description helps reviewers understand the context, approach, and impact of the changes.
6. If you have Github MCP, or gh cli is installed and authenticated then find the PR for the branch we analyzed and update the PR description there and then delete the PR_DESCRIPTION.md file. (If you have a better name (title) for the PR, go ahead and update the title too.{directory_context}"""

    # Return the prompt to be processed by the main chat system
    return pr_prompt


@register_command(
    name="wiggum",
    description="Loop mode: re-run the same prompt when agent finishes (like Wiggum chasing donuts üç©)",
    usage="/wiggum <prompt>",
    category="core",
)
def handle_wiggum_command(command: str) -> str | bool:
    """Start wiggum loop mode.

    When active, the agent will automatically re-run the same prompt
    after completing, resetting context each time. Use Ctrl+C to stop.

    Example:
        /wiggum say hello world
    """
    from code_puppy.command_line.wiggum_state import start_wiggum
    from code_puppy.messaging import emit_info, emit_success, emit_warning

    # Extract the prompt after /wiggum
    parts = command.split(maxsplit=1)
    if len(parts) < 2 or not parts[1].strip():
        emit_warning("Usage: /wiggum <prompt>")
        emit_info("Example: /wiggum say hello world")
        emit_info("This will repeatedly run 'say hello world' after each completion.")
        emit_info("Press Ctrl+C to stop the loop.")
        return True

    prompt = parts[1].strip()

    # Start wiggum mode
    start_wiggum(prompt)
    emit_success("üç© WIGGUM MODE ACTIVATED!")
    emit_info(f"Prompt: {prompt}")
    emit_info("The agent will re-loop this prompt after each completion.")
    emit_info("Press Ctrl+C to stop the wiggum loop.")

    # Return the prompt to execute immediately
    return prompt


@register_command(
    name="wiggum_stop",
    description="Stop wiggum loop mode",
    usage="/wiggum_stop",
    aliases=["stopwiggum", "ws"],
    category="core",
)
def handle_wiggum_stop_command(command: str) -> bool:
    """Stop wiggum loop mode."""
    from code_puppy.command_line.wiggum_state import is_wiggum_active, stop_wiggum
    from code_puppy.messaging import emit_info, emit_success

    if is_wiggum_active():
        stop_wiggum()
        emit_success("üç© Wiggum mode stopped!")
    else:
        emit_info("Wiggum mode is not active.")

    return True


@register_command(
    name="credentials",
    description="Show credential status for all model providers",
    usage="/credentials",
    aliases=["creds", "auth"],
    category="core",
)
def handle_credentials_command(command: str) -> bool:
    """Show credential status for all model providers."""
    from code_puppy.core.credential_availability import (
        get_credential_status,
        get_models_by_availability,
    )
    from code_puppy.messaging import emit_info

    status = get_credential_status()
    available, unavailable = get_models_by_availability()

    lines = ["## üîê Credential Status\n"]
    lines.append("### Providers\n")
    
    for provider, info in sorted(status.items()):
        symbol = "‚úÖ" if info["available"] else "‚ùå"
        if info["type"] == "api_key":
            lines.append(f"  {symbol} **{provider}**: `{info['key']}`")
        else:
            lines.append(f"  {symbol} **{provider}**: OAuth (`{info['plugin']}`)")
    
    lines.append(f"\n### Models Available: {len(available)}/{len(available)+len(unavailable)}")
    
    if available:
        lines.append("\n**Ready to use:**")
        # Group by first prefix
        prefixes = {}
        for m in available:
            prefix = m.split("-")[0]
            prefixes.setdefault(prefix, []).append(m)
        for prefix, models in sorted(prefixes.items()):
            lines.append(f"  ‚Ä¢ `{prefix}-*`: {len(models)} models")
    
    if unavailable:
        lines.append("\n**Missing credentials:**")
        prefixes = {}
        for m in unavailable:
            prefix = m.split("-")[0]
            prefixes.setdefault(prefix, []).append(m)
        for prefix, models in sorted(prefixes.items()):
            lines.append(f"  ‚Ä¢ `{prefix}-*`: {len(models)} models")

    emit_info("\n".join(lines))
    return True


@register_command(
    name="skills",
    description="Manage agent skills - browse, enable, disable skills",
    usage="/skills [list|enable|disable]",
    category="core",
    detailed_help="""Launch the skills TUI menu or manage skills with subcommands:
    /skills        - Launch interactive TUI menu
    /skills list   - Quick text list of all skills
    /skills enable - Enable skills integration globally
    /skills disable - Disable skills integration globally""",
)
def handle_skills_command(command: str) -> bool:
    """Handle the /skills command.

    Subcommands:
        /skills         - Launch interactive TUI menu
        /skills list    - Quick text list of all skills (no TUI)
        /skills enable  - Enable skills globally
        /skills disable - Disable skills globally
    """
    from code_puppy.command_line.skills_menu import show_skills_menu
    from code_puppy.messaging import emit_error, emit_info, emit_success, emit_warning
    from code_puppy.plugins.agent_skills.config import (
        get_skills_enabled,
        set_skills_enabled,
    )
    from code_puppy.plugins.agent_skills.discovery import discover_skills
    from code_puppy.plugins.agent_skills.metadata import parse_skill_metadata

    tokens = command.split()

    # Handle subcommands
    if len(tokens) > 1:
        subcommand = tokens[1].lower()

        if subcommand == "list":
            # Quick text list of all skills
            from code_puppy.plugins.agent_skills.config import get_disabled_skills

            skills = discover_skills()
            enabled = get_skills_enabled()
            disabled_skills = get_disabled_skills()

            if not skills:
                emit_info("No skills found.")
                emit_info("Create skills in:")
                emit_info("  - ~/.code_puppy/skills/")
                emit_info("  - ./skills/")
                return True

            emit_info(f"üõ†Ô∏è Skills (integration: {'enabled' if enabled else 'disabled'})")
            emit_info(f"Found {len(skills)} skill(s):\n")

            for skill in skills:
                metadata = parse_skill_metadata(skill.path)
                if metadata:
                    status = (
                        "üî¥ disabled"
                        if metadata.name in disabled_skills
                        else "üü¢ enabled"
                    )
                    version_str = f" v{metadata.version}" if metadata.version else ""
                    author_str = f" by {metadata.author}" if metadata.author else ""
                    emit_info(f"  {status} {metadata.name}{version_str}{author_str}")
                    emit_info(f"      {metadata.description}")
                    if metadata.tags:
                        emit_info(f"      tags: {', '.join(metadata.tags)}")
                else:
                    status = (
                        "üî¥ disabled" if skill.name in disabled_skills else "üü¢ enabled"
                    )
                    emit_info(f"  {status} {skill.name}")
                    emit_info("      (no SKILL.md metadata found)")
                emit_info("")

            return True

        elif subcommand == "enable":
            set_skills_enabled(True)
            emit_success("‚úÖ Skills integration enabled globally")
            return True

        elif subcommand == "disable":
            set_skills_enabled(False)
            emit_warning("üî¥ Skills integration disabled globally")
            return True

        else:
            emit_error(f"Unknown subcommand: {subcommand}")
            emit_info("Usage: /skills [list|enable|disable]")
            return True

    # No subcommand - launch TUI menu
    # Always return True so the command is consumed and not passed to LLM
    show_skills_menu()
    return True


@register_command(
    name="scheduler",
    description="Manage scheduled tasks - create, run, and monitor automated prompts",
    usage="/scheduler [start|stop|status|list|run <id>]",
    aliases=["sched", "cron"],
    category="core",
    detailed_help="""Launch the scheduler TUI menu or manage scheduled tasks:
    /scheduler        - Launch interactive TUI menu
    /scheduler start  - Start the scheduler daemon
    /scheduler stop   - Stop the scheduler daemon  
    /scheduler status - Show daemon status and task summary
    /scheduler list   - List all scheduled tasks
    /scheduler run <id> - Run a specific task immediately""",
)
def handle_scheduler_command(command: str) -> bool:
    """Handle the /scheduler command.

    Subcommands:
        /scheduler         - Launch interactive TUI menu
        /scheduler start   - Start the scheduler daemon
        /scheduler stop    - Stop the scheduler daemon
        /scheduler status  - Show daemon status
        /scheduler list    - List all tasks
        /scheduler run <id> - Run a task immediately
    """
    from code_puppy.command_line.scheduler_menu import show_scheduler_menu
    from code_puppy.scheduler.cli import (
        handle_scheduler_list,
        handle_scheduler_run,
        handle_scheduler_start,
        handle_scheduler_status,
        handle_scheduler_stop,
    )

    tokens = command.split()

    # Handle subcommands
    if len(tokens) > 1:
        subcommand = tokens[1].lower()

        if subcommand == "start":
            return handle_scheduler_start()
        elif subcommand == "stop":
            return handle_scheduler_stop()
        elif subcommand == "status":
            return handle_scheduler_status()
        elif subcommand == "list":
            return handle_scheduler_list()
        elif subcommand == "run":
            if len(tokens) < 3:
                emit_error("Usage: /scheduler run <task_id>")
                return False
            return handle_scheduler_run(tokens[2])
        else:
            emit_error(f"Unknown subcommand: {subcommand}")
            emit_info("Usage: /scheduler [start|stop|status|list|run <id>]")
            return False

    # No subcommand - launch TUI menu
    show_scheduler_menu()

